{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/mnist/tf/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Mechanics 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data\n",
    "--- \n",
    "MNIST is a classic problem in machine learning. The problem is to look at greyscale 28x28 pixel images of handwritten digits and determine which digit the image represents, for all the digits from zero to nine.\n",
    "<img, src='context/mnist_digits.png'>\n",
    "For more information, refer to Yann LeCun's MNIST page or Chris Olah's visualizations of MNIST.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Download\n",
    "\n",
    "At the top of the run_training() method, the input_data.read_data_sets() function will ensure that the correct data has been downloaded to your local training folder and then unpack that data to return a dictionary of DataSet instances.\n",
    "\n",
    "> data_sets = input_data.read_data_sets(FLAGS.train_dir, FLAGS.fake_data)\n",
    "\n",
    "NOTE: The fake_data flag is used for unit-testing purposes and may be safely ignored by the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Dataset|Purpose| \n",
    "|----|-----|\n",
    "|data_sets.train|\t55000 images and labels, for primary training.\n",
    "|data_sets.validation|\t5000 images and labels, for iterative validation of training accuracy.\n",
    "|data_sets.test|\t10000 images and labels, for final testing of trained accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data \n",
    "\n",
    "data_sets = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and Placeholders\n",
    "\n",
    "The placeholder_inputs() function creates two tf.placeholder ops that define the shape of the inputs, including the batch_size, to the rest of the graph and into which the actual training examples will be fed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\n",
    "                                                       mnist.IMAGE_PIXELS))\n",
    "\n",
    "\n",
    "> labels_placeholder = tf.placeholder(tf.int32, shape=(batch_size))\n",
    "\n",
    "Further down, in the training loop, the full image and label datasets are sliced to fit the batch_size for each step, matched with these placeholder ops, and then passed into the sess.run() function using the feed_dict parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,782])\n",
    "y_=tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Graph\n",
    "--- \n",
    "After creating placeholders for the data, the graph is built from the mnist.py file according to a 3-stage pattern: inference(), loss(), and training().\n",
    "\n",
    "1. inference() - Builds the graph as far as is required for running the network forward to make predictions.\n",
    "2. loss() - Adds to the inference graph the ops required to generate loss.\n",
    "3. training() - Adds to the loss graph the ops required to compute and apply gradients.\n",
    "\n",
    "<img src='context/mnist_subgraph.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "The inference() function builds the graph as far as needed to return the tensor that would contain the output predictions.\n",
    "\n",
    "It takes the images placeholder as input and builds on top of it a pair of fully connected layers with ReLu activation followed by a ten node linear layer specifying the output logits.\n",
    "\n",
    "Each layer is created beneath a unique tf.name_scope that acts as a prefix to the items created within that scope.\n",
    "> with tf.name_scope('hidden1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the defined scope, the weights and biases to be used by each of these layers are generated into tf.Variable instances, with their desired shapes:\n",
    "> weights = tf.Variable(\n",
    "    tf.truncated_normal([IMAGE_PIXELS, hidden1_units],\n",
    "                        stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))),\n",
    "    name='weights')\n",
    "    \n",
    "> biases = tf.Variable(tf.zeros([hidden1_units]),\n",
    "                     name='biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('hidden1'):\n",
    "    W=tf.Variable(tf.zeros([784,10]))\n",
    "    b=tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
